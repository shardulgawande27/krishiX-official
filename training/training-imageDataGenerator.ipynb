{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cdc7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd341dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95578c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1506 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=10,\n",
    "        horizontal_flip=True\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'dataset/train',\n",
    "        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "        batch_size=32,\n",
    "        class_mode=\"sparse\",\n",
    "#         save_to_dir=\"C:\\\\Code\\\\potato-disease-classification\\\\training\\\\AugmentedImages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05ec5988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Potato___Early_blight': 0, 'Potato___Late_blight': 1, 'Potato___healthy': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55208cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = list(train_generator.class_indices.keys())\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c06f7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.48467004 0.4258465  0.4376112 ]\n",
      "  [0.4613449  0.40252137 0.41428608]\n",
      "  [0.5005855  0.441762   0.4535267 ]\n",
      "  ...\n",
      "  [0.565658   0.5029128  0.5068344 ]\n",
      "  [0.52143294 0.45868784 0.4626094 ]\n",
      "  [0.4853577  0.4226126  0.42653418]]\n",
      "\n",
      " [[0.50485796 0.44603443 0.45779914]\n",
      "  [0.5091362  0.4503127  0.4620774 ]\n",
      "  [0.5460207  0.48719713 0.49896184]\n",
      "  ...\n",
      "  [0.500624   0.4378789  0.44180048]\n",
      "  [0.49720985 0.43446475 0.43838632]\n",
      "  [0.47356802 0.41082293 0.4147445 ]]\n",
      "\n",
      " [[0.52996224 0.47113872 0.48290342]\n",
      "  [0.5622919  0.5034684  0.5152331 ]\n",
      "  [0.57572967 0.5169061  0.5286708 ]\n",
      "  ...\n",
      "  [0.54757917 0.48483405 0.4887556 ]\n",
      "  [0.5704224  0.5076773  0.5115989 ]\n",
      "  [0.5206518  0.45790672 0.4618283 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.65721905 0.6140818  0.6376112 ]\n",
      "  [0.6648381  0.6217008  0.64523023]\n",
      "  [0.6731304  0.62999314 0.65352255]\n",
      "  ...\n",
      "  [0.7605717  0.72135603 0.7252776 ]\n",
      "  [0.75708836 0.7178727  0.72179425]\n",
      "  [0.7494709  0.7102552  0.7141768 ]]\n",
      "\n",
      " [[0.68467003 0.6415328  0.6650622 ]\n",
      "  [0.6885911  0.6454539  0.6689833 ]\n",
      "  [0.6927492  0.64961195 0.67314136]\n",
      "  ...\n",
      "  [0.7607844  0.72156864 0.7254902 ]\n",
      "  [0.75687605 0.71766037 0.72158194]\n",
      "  [0.74924535 0.71002966 0.71395123]]\n",
      "\n",
      " [[0.69365925 0.650522   0.6740514 ]\n",
      "  [0.693877   0.6507397  0.67426914]\n",
      "  [0.69758457 0.6544473  0.6779767 ]\n",
      "  ...\n",
      "  [0.7607844  0.72156864 0.7254902 ]\n",
      "  [0.75339967 0.7141839  0.7181055 ]\n",
      "  [0.74555653 0.7063408  0.71026236]]]\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for image_batch, label_batch in train_generator:\n",
    "#     print(label_batch)\n",
    "    print(image_batch[0])\n",
    "    break\n",
    "#     count+=1\n",
    "#     if count>2:\n",
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f392f176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 215 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=10,\n",
    "        horizontal_flip=True)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'dataset/val',\n",
    "        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "        batch_size=32,\n",
    "        class_mode=\"sparse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa1bdf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 431 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=10,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'dataset/test',\n",
    "        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "        batch_size=32,\n",
    "        class_mode=\"sparse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d271eb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.53450906 0.47176397 0.5149012 ]\n",
      "  [0.5432537  0.48050866 0.5236459 ]\n",
      "  [0.55407566 0.4913306  0.5344678 ]\n",
      "  ...\n",
      "  [0.53057474 0.47959432 0.51881003]\n",
      "  [0.53103876 0.48005837 0.51927406]\n",
      "  [0.5315028  0.4805224  0.5197381 ]]\n",
      "\n",
      " [[0.533813   0.47106794 0.51420516]\n",
      "  [0.54278976 0.4800446  0.5231819 ]\n",
      "  [0.55337965 0.49063453 0.5337718 ]\n",
      "  ...\n",
      "  [0.55868727 0.5077069  0.54692256]\n",
      "  [0.5610074  0.510027   0.5492427 ]\n",
      "  [0.56332743 0.51234704 0.5515627 ]]\n",
      "\n",
      " [[0.533117   0.4703719  0.51350915]\n",
      "  [0.5423257  0.4795806  0.52271783]\n",
      "  [0.5526836  0.48993853 0.53307575]\n",
      "  ...\n",
      "  [0.567492   0.5165116  0.5557273 ]\n",
      "  [0.567028   0.5160476  0.5552633 ]\n",
      "  [0.56656396 0.5155836  0.55479926]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.51413643 0.46315604 0.5023717 ]\n",
      "  [0.5122803  0.46129993 0.50051564]\n",
      "  [0.51042426 0.45944384 0.49865952]\n",
      "  ...\n",
      "  [0.5879777  0.5605267  0.5879777 ]\n",
      "  [0.58593696 0.5584859  0.58593696]\n",
      "  [0.60711294 0.57966197 0.60711294]]\n",
      "\n",
      " [[0.4828188  0.43183842 0.4710541 ]\n",
      "  [0.48096275 0.42998233 0.46919805]\n",
      "  [0.47910663 0.42812625 0.46734193]\n",
      "  ...\n",
      "  [0.5886738  0.5612228  0.5886738 ]\n",
      "  [0.5850089  0.55755794 0.5850089 ]\n",
      "  [0.6052569  0.57780594 0.6052569 ]]\n",
      "\n",
      " [[0.47255293 0.42157254 0.46078822]\n",
      "  [0.47603312 0.4250527  0.46426842]\n",
      "  [0.47951326 0.42853287 0.46774855]\n",
      "  ...\n",
      "  [0.58936983 0.5619188  0.58936983]\n",
      "  [0.5840808  0.55662984 0.5840808 ]\n",
      "  [0.60340077 0.5759498  0.60340077]]]\n"
     ]
    }
   ],
   "source": [
    "for image_batch, label_batch in test_generator:\n",
    "    print(image_batch[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e6ac0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "n_classes = 3\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=input_shape),\n",
    "    layers.Conv2D(32, kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(n_classes, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00332e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 2, 2, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 183,747\n",
      "Trainable params: 183,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cd872ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9db525dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.0625"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "1506/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d31735a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.71875"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "215/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=47,\n",
    "    batch_size=32,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=6,\n",
    "    verbose=1,\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8b7bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf0985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd40e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae35d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1387a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c35b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a317942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['loss'][:5] # show loss for first 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc2e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31667c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de784a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c251909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(EPOCHS), acc, label='Training Accuracy')\n",
    "plt.plot(range(EPOCHS), val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(EPOCHS), loss, label='Training Loss')\n",
    "plt.plot(range(EPOCHS), val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0365cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "for image_batch, label_batch in test_generator:\n",
    "    first_image = image_batch[0]\n",
    "    first_label = int(labels_batch[0])\n",
    "    \n",
    "    print(\"first image to predict\")\n",
    "    plt.imshow(first_image)\n",
    "    print(\"actual label:\",class_names[first_label])\n",
    "    \n",
    "    batch_prediction = model.predict(images_batch)\n",
    "    print(\"predicted label:\",class_names[np.argmax(batch_prediction[0])])\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6232e567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img):\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(images[i])\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    predicted_class = class_names[np.argmax(predictions[0])]\n",
    "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fa30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "for images, labels in test_generator:\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        \n",
    "        predicted_class, confidence = predict(model, images[i])\n",
    "        actual_class = class_names[int(labels[i])] \n",
    "        \n",
    "        plt.title(f\"Actual: {actual_class},\\n Predicted: {predicted_class}.\\n Confidence: {confidence}%\")\n",
    "        \n",
    "        plt.axis(\"off\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac6c354",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../potatoes1.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
